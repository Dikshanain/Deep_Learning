{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ttLZkP0fPX4AFEP-8uIEC359OVjruhVa",
      "authorship_tag": "ABX9TyNCDm/qSpFh/+8fyXK3sBzX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dikshanain/Deep_Learning/blob/main/Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FNf3N1NUCKbx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()"
      ],
      "metadata": {
        "id": "ahmIB0-aCVbL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images=train_images.reshape((60000,28,28,1)).astype('float32')/255\n",
        "test_images=test_images.reshape((10000,28,28,1)).astype('float32')/255"
      ],
      "metadata": {
        "id": "uXKfBqBCDYcv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_resized=tf.image.resize(train_images,(32,32))\n",
        "test_images_resized=tf.image.resize(test_images,(32,32))"
      ],
      "metadata": {
        "id": "Y4aOUrCLDcRv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_rgb=tf.image.grayscale_to_rgb(train_images_resized)\n",
        "test_images_rgb=tf.image.grayscale_to_rgb(test_images_resized)"
      ],
      "metadata": {
        "id": "66aodqGODuK0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels=to_categorical(train_labels,10)\n",
        "test_labels=to_categorical(test_labels,10)"
      ],
      "metadata": {
        "id": "mvLsnuADD_QP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a pretrained MobileNetV2 model without classification layer"
      ],
      "metadata": {
        "id": "NHK3ndgtEJ0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model=VGG16(weights='imagenet',include_top=False,input_shape=(32,32,3))"
      ],
      "metadata": {
        "id": "vDRMoY41EDVZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze pretrained layers"
      ],
      "metadata": {
        "id": "fhlzHs8BEW0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable=False"
      ],
      "metadata": {
        "id": "KwS33jLbEU-x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add custom layers on top of the pre-trained\n",
        "model"
      ],
      "metadata": {
        "id": "D7hy4nmTEevj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=models.Sequential([\n",
        "    base_model,   #use VGG16 as the feature extractor\n",
        "    layers.Flatten(),    # Flatten the output of VGG16 to feed it to the Dense layer\n",
        "    layers.Dense(64,activation='relu'),    # Add a Dense layer with 64 units and ReLU activation\n",
        "    layers.Dense(10,activation='softmax')     # Output layer for classification into 10 classes (digits)\n",
        "])"
      ],
      "metadata": {
        "id": "VcuqEeC7EdDB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model"
      ],
      "metadata": {
        "id": "aKWeu8AdFSDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fhZwqzGkFRPV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evaluate"
      ],
      "metadata": {
        "id": "QNDIy2u8FYne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_images_rgb, train_labels,epochs=5, batch_size=64, validation_split=0.2)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images_rgb,\n",
        "test_labels)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbIl40IDFXid",
        "outputId": "56e76cc7-4ae7-4320-8413-fdbe534bbbbd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.7256 - loss: 0.9567 - val_accuracy: 0.9288 - val_loss: 0.2503\n",
            "Epoch 2/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9326 - loss: 0.2302 - val_accuracy: 0.9478 - val_loss: 0.1726\n",
            "Epoch 3/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9493 - loss: 0.1699 - val_accuracy: 0.9557 - val_loss: 0.1420\n",
            "Epoch 4/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9590 - loss: 0.1375 - val_accuracy: 0.9594 - val_loss: 0.1301\n",
            "Epoch 5/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.1260 - val_accuracy: 0.9597 - val_loss: 0.1289\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9572 - loss: 0.1314\n",
            "Test Accuracy: 0.9616000056266785\n"
          ]
        }
      ]
    }
  ]
}